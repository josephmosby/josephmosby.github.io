<!doctype html>
<html>
	<head>

		<title>josephmosby.com</title>
		<meta http-equiv="Content-Type" content="text/html" charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link rel="stylesheet" href="/stylesheets/fibonacci.css" />
		<link rel="stylesheet" href="/stylesheets/custom.css" />

		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>

	</head>

	<body>

		<div class="wrapper" id="header">
			<div class="container">
				<div class="row">
					<div class="col-13">
						<a href="/"><h3>JOSEPH MOSBY</h3></a>

						<ul class="menu inline">
							<li><a href="/about">about</a></li>
							<li><a href="/projects">projects</a></li>
							<li><a href="/presentations">presentations</a></li>
							<li><a href="/now">now</a></li>
							<li><a href="/feed/atom.xml">subscribe</a></li>
						</ul>

						<a id="hamburger" href="#">MENU</a>
					</div>
				</div>
			</div>
		</div>

		<div class="wrapper" id="dropdown">
			<div class="container">
				<div class="row">
					<div class="col-13">
						<ul class="menu dropdown">
							<li><a href="/about">about</a></li>
							<li><a href="/projects">projects</a></li>
							<li><a href="/presentations">presentations</a></li>
							<li><a href="/now">now</a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>

		<div class="wrapper" id="main">
			<div class="container">
				
<div class="row">
	<div class="col-3">
		<a href="/2014/08/26/the-magic-in-the-machine.html"><h3>The Magic in the Machine</h3></a>
		<div class="date">August 26, 2014</div>
	</div>
	<div class="col-8">
		<p>Our love affair with computers has a long, complex history. We did not fall in love with them because they allowed us to be more productive. Nor did we love them because they encouraged us to talk to our friends over the Internet. Our first love affair began a decade before the web, when the first PCs gave software developers the ability to create new and interesting art forms such as Tron, The Last Starfighter and Castle Wolfenstein. It is creative computing, the creation of art out of code, that has always resonated with us. Creative computing is what excites us about our devices and keeps drawing us in for more.</p>

<p>Yet as the computer invades every aspect of our personal and professional lives, we have sacrificed that original magic for efficiency. Digital design concepts and capabilities have improved exponentially over the years, but the trends have been toward flat, functional, sterile, clean design. Hardware products have emphasized simple screen real estate while removing as much of the surrounding matter as possible. Web design is focused on maximizing “conversions” while optimizing for machines to add to search engine indexes.</p>

<p>A craving for efficiency in creative computing implies that we have a host of vaguely unpleasant tasks to accomplish on the machine, so we should make it as easy as possible for users to get to what they need to do quickly and get out. Creative computing is becoming a race to find the hyper-optimized, mechanical place where users can move through their fast food assembly line of digital tasks so they can move to the next fast food assembly line of digital tasks, over and over again in perpetuity. There is no joy at the end of this tunnel.</p>

<p>In the real world, the joy has always been outside the screen, and creative computing at its best is a way to augment our experiences with and memories of that world. It’s not the cold pixel representation of some meat on a plate in an Instagram feed; it’s the memory of the fantastic steak dinner date with a group of friends you’ve known since college that truly brings us joy. That silly Instagram shot is just a reminder that brings a memory to life in our minds. Even for millennials or post-millennials who grew up with the Internet and entered the working world armed with smart phones and social media accounts, our joy has never been contained inside a screen.</p>

<p>Psychologists, sociologists, neuroscientists and anthropologists have spent years on soapboxes shouting about the dangers of too much screen use, evidenced by <a href="http://www.dailymail.co.uk/sciencetech/article-2175230/Too-time-online-lead-stress-sleeping-disorders-depression.html">screen-induced sleeping disorders</a> and <a href="http://www.huffingtonpost.com/2012/11/28/south-korea-internet-addicted_n_2202371.html">Internet addiction centers</a>. Yet these complaints are so often branded as a problem of the Internet itself, that there is some inherent problem with our computing-enabled society. Our computers and our Internet connections are not the problem: like the TV revolution decades before, our insistence on staring at a single glowing screen for hours on end is a problem.</p>

<p>It is time for creative computing to break out of its screen. It is time for us to rekindle the magic of computing on a familiar ground we still love: the real world.</p>

<p>For a long time, the wizardry of blurring the lines of the physical and the digital world was a cost-prohibitive proposition for most creative campaigns. Most technologists, creative agencies and marketing departments simply could not afford the infrastructure required to connect the two worlds. That landscape has now changed. Our audiences are equipped with cameras, GPS devices, and microphones in their mobile devices at all times. Inexpensive microcontrollers now allow software developers to play with sensors and electronic devices with ease. The ubiquity of wireless networks allows us to connect a vast array of devices over the air at any time.</p>

<p>We have already begun experimenting with these tools in our own D.C. office, with a website that lets a colleague who recently moved to Seattle manipulate the lights at his old desk. The possibilities are endless; these tools allow us to build anything our minds can imagine. They grant us the ability to jump back and forth between worlds, to split our interactions between the physical and the digital in ways that science fiction could only dream of decades earlier. We no longer need to restrict ourselves to dreaming about these things – their secrets have been unlocked, and they can be built at any time.</p>

<p>The next wave of creative computing and the future digital marketing and PR campaigns it spawns will not be restricted to an audience’s screens. They will touch them where they live, in the real world. They will be there for audiences to touch, feel, smell and experience without needing to reach for a portable glowing screen. They will make the machine invisible and will share an audience’s joy when magical, unexpected things begin to happen in the real world, things that creative computing will enable and inspire.</p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/08/26/the-magic-in-the-machine.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/05/28/ford-mosbys-amazing-burger-recipe.html"><h3>Ford Mosby's Amazing Burger Recipe</h3></a>
		<div class="date">May 28, 2014</div>
	</div>
	<div class="col-8">
		<p>I like to think that the parts of my brain that like programming and the parts of my brain that like cooking are somehow intricately linked. I have a tendency to start out with a stack of recipes as “inspiration” and then improvise the rest on the spot, and that certainly reveals itself in my coding style as well. And now that I’m improving as a programmer and investigating rules and frameworks, I’m following recipes far more closely. This might all be coincidence, and it might just be a sign that I’m maturing as a <strong>human being</strong> rather than as a programmer or cook, but I’m going to say it’s all linked until proven otherwise.</p>

<p>My mom cooks far more than my dad. I inherited quite a bit from her and still consult her on techniques and ideas all the time. She would never admit that she was a great cook, but I was spoiled so much on home-cooked meals from her over the years that I simply had to start doing the same when I moved into my own apartment. Dad was the grillmaster, though, and this is the simple recipe he’s most known for. Good food is meant to be shared. </p>

<h3 id="dads-burgers">Dad’s Burgers</h3>

<p>You will need:</p>

<ul>
  <li>ground beef, 80% lean, poundage based on how many people you’re feeding (I like to go around 1/2 lb per person, leftovers aren’t a bad thing)</li>
  <li>eggs</li>
  <li>worcestershire sauce</li>
  <li>salt</li>
  <li>pepper</li>
  <li>garlic powder</li>
</ul>

<p>Prepare the patties:</p>

<ol>
  <li>Start your grill to crank it to about 400°.</li>
  <li>Dump all of your burger meat into a big bowl. </li>
  <li>For each pound of meat, crack a whole egg into the bowl. </li>
  <li>Add a tablespoon and a half of worcestershire, a teaspoon of salt, a teaspoon of pepper and a teaspoon of garlic powder per pound of meat.</li>
  <li>Get your hands into that meat and start massaging those eggs into it. Don’t be shy about it. Get it all mixed in there.</li>
  <li>With your hands, scoop out a handful of meat about the size of a baseball. Turn it around in your hands to compress it into a round ball.</li>
  <li>Press the ball of meat into a cookie sheet. Flatten it until it’s about 2/3 of an inch thick.</li>
  <li>Repeat until all of your meat is formed into burgers. Don’t leave leftover raw meat.</li>
  <li>Slap each of those burgers on the grill and shut the top quickly. <em>Don’t leave your grill top open.</em></li>
  <li>Wait four minutes, then flip them. Shut the top again.</li>
  <li>Wait four minutes, then check them. When you poke the burgers, they should be a bit springy, not soggy. </li>
  <li>If not springy yet, flip them once more, give them two minutes, then pull them out. </li>
</ol>

<p>Voilà. With your own two hands and fire, you have produced burgers. Maybe melt some cheese on top of them next time or toast the buns. The summer is yours to conquer.</p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/05/28/ford-mosbys-amazing-burger-recipe.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/04/18/a-modest-proposal-for-accessibility-driven-web-development-for-government.html"><h3>A Modest Proposal for Accessibility-Driven Web Development within Government</h3></a>
		<div class="date">April 18, 2014</div>
	</div>
	<div class="col-8">
		<p>I have never been a developer specifically tasked with making web applications accessible to users with disabilities, but I still find myself engaged in conversations about web accessibility with my friends employed by government agencies here in Washington, D.C. There is always some new service or technology or design that government employees would love to bring in, but they’re not legally allowed to because it’s not “Section 508-compliant.” This inevitably sparks a conversation about making technology accessible, and it’s all too often sparked by non-developers who can’t understand why developers just can’t make their products accessible. It’s one of the most misunderstood problems facing the accessibility community, and it shows no signs of being resolved any time soon. </p>

<p>I would be remiss if I tried to solve the entire web accessibility problem in a blog post, but I can hopefully shed some light on how the problems start - now that I’ve had the opportunity to fix a few of my own.</p>

<p>Recently, my team was tasked to make some changes to a web site with a map that showed text content when a user hovered over it. I can’t show the site itself, but <a href="https://www.mapbox.com/mapbox.js/example/v1.0.0/show-tooltips-on-hover/">this page</a> gives a decent representation of what we added. It’s a red-flag accessibility problem because it implies that sight is required to operate the web application, and not every possible user can see the screen. Some are navigating it through screen readers. I’ve had some training in how to spot these sorts of things, though, and I realized that we could easily just head off the user by placing <code>aria</code> tags within the map when a user stumbled upon it, and we could also place the tooltips in the HTML document such that a user could still read them. This was about five minutes worth of extra work, and all I needed to do was organize my HTML in such a way that a screen reader could figure it out. </p>

<p>I can do this because I’m not just thinking about accessibility (which would have caused me to forego the map idea altogether), and I’m not just trying to hammer out a task in a hurry (which would have caused me to skip the HTML rearrangement). I’ve got time and training to notice the problem and creatively solve it. That happens at every level with our team at <a href="http://www.apcoworldwide.com">APCO Worldwide</a>. Our team members developing wireframes and user interfaces have accessibility in the back of their mind, our designers are thinking about color contrasts and font choices, and our developers are sorting through their HTML to make sure we don’t make some sort of confusing error in our code. We’re not accessibility professionals, we’re creative professionals who happen to know that not every user has the same experience with a computer that we do.</p>

<p>We also plan our designs and our development in a holistic manner, and we iterate through multiple rounds of feedback to get it right. We decide who gets to have feedback and who doesn’t. And we don’t just say “yes” to any change that comes down the pipe: we weigh changes through our creative expertise before we implement them, and we push back on our clients if they make changes that will be problematic. If a client requests something that’s going to impact the accessibility of the site (such as a color contrast issue or a font change), we discuss it internally and propose alternatives before we just start coding. </p>

<h3 id="what-government-gets-wrong">What Government Gets Wrong</h3>

<p>Government has recently taken an interest in good design, which is all for the best. But it has focused heavily on simply hiring individual designers rather than <em>focusing on a creative process that emphasizes excellent, accessible design throughout.</em> This requires a commitment to a management style that is inherently at odds with how government develops and deals with IT solutions. </p>

<p>Government tends to want to shift all the blame for bad, inaccessible design on contractors, but I don’t think that’s the whole of the problem. We pull off accessible design well and we’re a contract-based shop. Our team is fortunate enough to be trusted to do our jobs and left to work, relatively uninterrupted, for decent blocks of time. Despite my contractor nature, my clients trust me to get my job done and don’t particularly care where or how I do it, so long as the end product is exactly what they asked for. Any government contractor will testify that this is typically not the case in the government.</p>

<p>Rather, you’re in an environment where the agency’s security office has insisted that you must work in their office on their machines at the time of day that they specify, you’re confronted with at least six half-hour to one-hour meetings per day from every project manager trying to use the same contractors for their own projects, and your design sensibilities will be whittled away by the occasional SES manager who just loves the color orange and really can’t understand why you can’t incorporate some orange into the design. Trust me, government project managers, I know that none of you is individually that bad. Collectively, however, there is a management culture within government that does not tolerate the daily structure required to consistently execute excellent, accessible design. </p>

<p>I know how we address this issue within our firm, and I imagine that the government solution to this problem is quite similar. We employ a “traffic manager” whose job is strictly to keep the designers on task and away from distractions by handling all of the overhead and scheduling that tries to plague them. Invoices, client meetings, rush projects - the traffic manager handles it all, and gives the designers direction on where to go each day. If a designer needs time to finish a deliverable, they tell the traffic manager about it before going offline - and if you happen to have some rush project that absolutely needs doing that day, you go through the traffic manager first. </p>

<p>The traffic manager is there to put a halt to one of the most basic problems with organizational culture: individually, no one is really a problem in the way of creative work. It’s when we all individually have problems at the same time that we become a collective, pervasive problem. The traffic manager is there to put a bottleneck to that collective problem. Can government bring in that sort of management style to fix its accessible design issues? Absolutely.</p>

<h3 id="what-about-externally-developed-products">What About Externally-Developed Products?</h3>

<p>Government agencies make use of Facebook, Twitter, and a host of other services that were not put together by contractors. Those services are all too often inaccessible to their detriment. But after thinking on <em>where</em> these products are developed, it doesn’t surprise me. Washington, D.C. confronts accessibility issues every day while other tech capitals rarely face it.</p>

<p>Growing up in the Southeast, I went my entire life never regularly interacting with vision- or hearing-impaired individuals. The city has almost no public transportation, which makes it difficult for the vision-impaired to independently get around. It’s a little bit easier on the hearing-impaired - but nothing compared to living near <a href="https://www.gallaudet.edu/">Galludet University</a> where the bartenders know sign language. This is the environment for much of the country, and it’s certainly the environment where these web services are being constructed. If we want accessible web services built by default, we have to constantly remind those developers if they aren’t going to regularly interact with users who can’t fully see the screen or hear a video. </p>

<p>And, to be honest, we’re going to have to make a case for it. Less than 3% of all Americans have some form of vision impairment that can’t be fully corrected. Of that group, most are over the age of 65 - hardly the target market for Twitter’s developers if we’re trying to convince them of a large new market out there. We must instead focus on the concept of access to information, and the importance of the information we want to convey. When Egypt’s access to many Internet services was shut down during a wave of protests, <a href="http://www.theguardian.com/technology/2011/feb/01/google-twitter-egypt">Google and Twitter stepped up</a> to provide access to Twitter via standard phone connections. Access to information is in these companies’ DNA, and that’s where we have to focus our accessibility efforts. Section 508, WCAG, etc., etc., don’t matter - what matters is that we have users who cannot access important information, and only these externally-developed services can help us get those messages out. </p>

<hr />

<p>Can these problems be solved? I think so. We need only break outside of our bubbles - both within Washington, DC government culture and without - and realize that there is a different way of doing business outside of our walls. </p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/04/18/a-modest-proposal-for-accessibility-driven-web-development-for-government.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/04/12/choosing-a-development-platform-to-reach-the-right-users.html"><h3>Choosing a Game Development Platform to Reach the Right Users</h3></a>
		<div class="date">April 12, 2014</div>
	</div>
	<div class="col-8">
		<p>Last Friday, I attended the <a href="http://www.media4socialimpact.org/">Media for Social Impact</a> Summit at the United Nations headquarters in NYC. Aside from the awesomeness of attending a conference at the United Nations, the summit was a really enlightening experience crammed into a single day’s worth of sessions. Each group of panelists focused on the most effective way to run an issue-based campaign with a social change in mind on a particular type of media. Of particular interest to me was the talk by Asi Burak of <a href="http://www.gamesforchange.org/">Games for Change</a>, whose <a href="https://www.facebook.com/HalftheGame">Half the Sky</a> game was designed to raise funds to empower women and girls.</p>

<p>Half the Sky is a Facebook game, a medium that I had admittedly often dismissed due to FarmVille and the like. I knew there were a ton of players on Facebook - 40 million monthly active users on Facebook for Farmville 2, <a href="http://www.polygon.com/2013/1/4/3837236/farmville-2-infographic-40-million-monthly-active-users">for example</a> - but really, why would I consider Facebook when there’s so much interesting stuff to be done on Steam or Xbox Live? Why would I tie my game to the constraints of a web browser when I could harness the entire power of a computer instead? </p>

<p>I had forgotten an extremely critical thing for a game of this nature. This was not a typical game that wanted its hands on every single possible user, but a game with a specific theme that needed to target a particular type of user. This game was designed to empower women and girls, and thus it needed to be on a platform that had a lot of women and girls playing games. That platform isn’t Xbox Live, or Steam, or PS3.. it’s Facebook. This game needed to reach a target audience at the lowest possible cost, and that meant Facebook development.</p>

<p>This was jaw-dropping for me as a developer who had never considered aligning the users I thought would be most interested in my game with the platform where those users hung out. And I’d also forgotten that the type of game (whether it’s strategy, turn-based, shooter, etc., etc.) is also going to be important to attract a certain type of audience. Let’s take a look at some examples:</p>

<h3 id="i-want-to-target-women-between-the-ages-of-35-and-50">I Want to Target Women Between the Ages of 35 and 50</h3>

<p>According to research by <a href="http://blog.apptopia.com/game-demographics-that-every-developer-should-know/">Apptopia and Flurry Analytics</a>, you need to take a look at slot machines or a “social turn-based” game (think FarmVille) if you want a game that’s going to appeal to women between the ages of 35 and 50. Think back to every time you’ve walked through a casino and wondered who actually played all of those slot machines - if you saw customers, they were likely right in that demographic. And you might consider a Facebook game - <a href="https://www.mediabistro.com/alltwitter/social-media-user-demographics_b38095">72% of female U.S. Internet users are on Facebook</a> - and you’re likely going to want to promote it on Pinterest as well. Go after ad partners who are targeting this demographic and show them the numbers.</p>

<h3 id="i-want-to-target-men-between-the-ages-of-20-and-30">I Want to Target Men Between the Ages of 20 and 30</h3>

<p>Let’s go back to that <a href="http://blog.apptopia.com/game-demographics-that-every-developer-should-know/">Apptopia piece</a>. You’re talking shooter games, RPGs, strategy games. If it’s an absolute requirement that you have regular return visitors, you need to put that strategy cap on.. but if you can get by with casual players, go for the shooters instead. You know that Pinterest isn’t worth your promotional efforts, but Twitter might be. And given the type of games that are popular on Steam (shooters, RPGs, and strategy), you certainly might want to take a look at launching there to promote to a heavily male audience. </p>

<p>None of this is an exact science, of course. You’ve still got to make a quality game and promote it the right way for it to take off. But you’re going to start off behind if you don’t take these things into consideration, and after developing a game for months at a time - you definitely don’t want to flop because you chose the wrong place to put your game.</p>

<p>TL;DR:</p>

<p><img src="/images/badtime.jpg" alt="If you promote a first person shooter on Pinterest, you're gonna have a bad time" /></p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/04/12/choosing-a-development-platform-to-reach-the-right-users.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/04/03/playlist-choices-for-the-month-of-april.html"><h3>Playlist Choices for the Month of April</h3></a>
		<div class="date">April 03, 2014</div>
	</div>
	<div class="col-8">
		<p>Every month, I start a brand new playlist that I fill with music over the course of the month. By the end of the first week, I share out what I’ve got so far. I’ve currently got Avicii’s “Hey Brother” stuck in my head and my playlist starts with that in mind. You’ll see some of both the EDM and old country/blues influences in this mix. </p>

<ol>
  <li>Lyle Lovett - “I Will Rise Up / Ain’t No More Cane”</li>
  <li>Avicii - “Hey Brother”</li>
  <li>Robert Randolph &amp; the Family Band - “Going in the Right Direction”</li>
  <li>The Delta Saints - “Company of Thieves”</li>
  <li>Eric Clapton and B.B. King - “Riding with the King”</li>
  <li>Pharrell Williams - “Happy”</li>
  <li>Cage the Elephant - “Ain’t No Rest for the Wicked”</li>
  <li>Eisley - “Marvelous Things”</li>
  <li>The 1975 - “Chocolate”</li>
  <li>Bastille - “Pompeii (Audien Remix)”</li>
  <li>Gorillaz - “Feel Good Inc.”</li>
  <li>Calvin Harris - “Summer”</li>
  <li>Gareth Emery &amp; Krewella - “Lights &amp; Thunder”</li>
</ol>

<p><a href="http://open.spotify.com/user/josephmosby/playlist/3CkL8xxAW7n7SYmOHg61jc">April 2014 - Spotify playlist</a></p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/04/03/playlist-choices-for-the-month-of-april.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/04/03/hacking-confirmation-emails-on-the-fly-with-mailgun.html"><h3>Hacking Confirmation Emails on the Fly with Mailgun</h3></a>
		<div class="date">April 03, 2014</div>
	</div>
	<div class="col-8">
		<p>I just finished slinging together some code for a confirmation email system for an email advocacy campaign using <a href="http://corporate.cqrollcall.com/cqrcengage">CQRC Engage</a>. Engage has a fairly simple set of tricks: it provides you with a Javascript-based widget to write a letter to your legislators, then submits that letter through whichever digital channel the legislator uses. As part of its process, it runs a check to find your particular legislator based on street address and postal code, then tailors the messages for that particular person. Engage doesn’t have an email confirmation sent to you as part of your advocacy, so I built one.</p>

<p>Engage accepts letter submissions via that Javascript widget, then stores data about that advocate, the target, and the message itself in a database accessible via an API. This is all we need to begin constructing our confirmation email system. We’re going to use <a href="http://www.mailgun.com">Mailgun</a> for this task, which is an API-based system that accepts HTTP POST requests and turns them into emails at your command. Without further ado, let’s start building.</p>

<p>I’m first going to build out a series of tiny classes that I’ll use to power my app. In this case, we’ll need four: one for the Advocate who sent a message, one for the Target, one for the Sent Message, and one for the Confirmation Email. They look something like this:</p>

<p>```python
class Advocate:
	def <strong>init</strong>(self, first_name, last_name, email):
		self.first_name = first_name
		self.last_name = last_name
		self.email = email</p>

<p>class Target:
	def <strong>init</strong>(self, first_name, last_name, title):
		self.first_name = first_name
		self.last_name = last_name
		self.title = title</p>

<p>class SentMessage:
	def <strong>init</strong>(self, sender, recipients, message_subject, message_text):
		self.sender = sender # who should be an Advocate
		self.recipients = recipients # a list of Targets
		self.message_subject = message_subject
		self.message_text = message_text</p>

<p>class ConfirmationEmail:
	def <strong>init</strong>(self, sent_message):
		self.message_sent = sent_message
```</p>

<p>This is all stuff I’m going to extract from Engage without any further processing. I’m also going to go ahead and construct my confirmation email template using Jinja’s syntax, which will accept data from these classes you see above.</p>

<p>```</p>
<html>
	<head>
		<meta charset="UTF-8" />
	</head>
	<body>
		<p>Dear {{ first_name }} {{ last_name }}:</p>
		
		<p>{{ confirmation_leadin }}</p>
		
		{% for recipient in recipients  %}
			{{ recipient.first_name }} {{ recipient.last_name }}, {{ recipient.title }}
			<br />
		{% endfor %}
		
		<br />
		
		<p>SUBJECT: {{ message_subject }}</p>
		
		{{ message_text }}
	</body>
</html>
<p>```</p>

<p>So far so good. You can see here that we’ve got a “confirmation_leadin” variable that doesn’t seem to line up with any of our other tags. We added some introductory text into our emails as a “thank you” before including the text of the message and the list of targets it was sent to. Next step is to add on some basic work to begin converting the plain text messages out of Engage into HTML-based messages using <a href="https://pythonhosted.org/Markdown/reference.html">Markdown</a>. Then we’ll use that, along with some of the data from our classes, to populate our Jinja template.</p>

<p>```python
# other lines truncated for brevity
class ConfirmationEmail: 
	def <strong>init</strong>(self, sent_message):
		self.message_sent = sent_message
		self.sanitized_message = markdown.markdown(sent_message.message_text, safe_mode=’replace’)</p>

<pre><code>def create_confirmation_text(self):
	self.confirmation_message = template.render( 
								{"first_name" : self.message_sent.sender.first_name,
							   	"last_name" : self.message_sent.sender.last_name, 
							   	"targets" : self.message_sent.recipients,
							   	"confirmation_leadin" : CONFIRMATION_LEADIN,
							   	"message_subject" : self.message_sent.message_subject,
							   	"message_text" : self.sanitized_message}) ```
</code></pre>

<p>We’re almost there! But now we just need to actually fire off that email, which requires a simple HTTP request using the <a href="http://docs.python-requests.org/en/latest/">requests</a> library.</p>

<p>```python
# other lines truncated for brevity
class ConfirmationEmail: 
	def <strong>init</strong>(self, sent_message):
		self.message_sent = sent_message
		self.sanitized_message = markdown.markdown(sent_message.message_text, safe_mode=’replace’)</p>

<pre><code>def create_confirmation_text(self):
	self.confirmation_message = template.render( 
								{"first_name" : self.message_sent.sender.first_name,
							   	"last_name" : self.message_sent.sender.last_name, 
							   	"targets" : self.message_sent.recipients,
							   	"confirmation_leadin" : CONFIRMATION_LEADIN,
							   	"message_subject" : self.message_sent.message_subject,
							   	"message_text" : self.sanitized_message})

def send_confirmation_message(self):
	return requests.post(MAILGUN_DOMAIN, auth=("api",API_KEY), 
							data={"from": DEFAULT_SENDER,
								  "to": [self.message_sent.sender.email],
								  "subject": CONFIRMATION_SUBJECT,
								  "html": self.confirmation_message}) ```
</code></pre>

<p>We need one final bit to tie it all together - our script that checks the Engage system for new messages, downloads the data and then generates email templates out of it. I’m using pseudocode for some of the Engage API calls, but you’ll get the general idea.</p>

<p>```python
if <strong>name</strong> == “<strong>main</strong>”:
	token = cq.login(‘user’,’password’)
	actions = getActions(token)</p>

<pre><code># store Actions to our owned database
# the StoreActions formula was all written to check for anything already in the database and filter out those results

conn = db.connect('db-location')	
storeActions(conn, actions)

# now we retrieve unconfirmed actions
# this returns me a dictionary in the format { advocateId: {messageId: X, targets: [Y, Z, ...]}}  

unconfirmed = cq.retrieveAllUnconfirmed(conn)

for advocateId in unconfirmed.keys():
	advocate = cq.getAdvocate(token, advocateId)
	sender = Advocate(first_name = advocate["first_name"], last_name = advocate["last_name"], email = advocate["email"])
	recipients = []
	for targetId in unconfirmed[advocateId]["targets"]:
		target = cq.getTarget(token, targetId)
		recipients.append(Target(first_name = target["first_name"], last_name = target["last_name"], title = target["title"]))
	
	message_delivered = cq.getMessage(token, unconfirmed[advocateId]["messageId"])
	sent_message = SentMessage(sender = sender, recipients = recipients, message_subject = message_delivered["message_subject"], message_text = message_delivered["message_body"])
	
	confirmation_email = ConfirmationEmail(sent_message)
	confirmation_email.create_confirmation_text()
	
	confirmation_email.send_confirmation_email()
 
# then finally, mark those as confirmed in our database

cq.markAsConfirmed(conn, unconfirmed.keys())
</code></pre>

<p>And that’s it. We’ve built out a confirmation email system using Python - not very pretty, but it sure knows how to get the job done. Our final task is to run this puppy on a schedule using cron:</p>

<p><code>$ env EDITOR=nano crontab -e</code></p>

<p><code>
*/3 * * * * /path/to/your/script
</code></p>

<p>That will set up a cron job that runs every 3 minutes and executes our confirmation email script. We’re ready to run this live, and – barring anything catastrophic like a server crash – it’s relatively error proof. The script is designed to just fail silently and re-open every session if a script can’t finish execution, so if a script misfires we’ll just pick up those confirmation emails in the next batch three minutes later.</p>

<p>I’m a Mailgun convert after this. It’s perfect for setting up simple email messages and automating them. The fact that I hacked this together in a few hours with most of that time dedicated to parsing through Engage’s API documentation shows the ease of Mailgun’s system. I’m all for it.</p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/04/03/hacking-confirmation-emails-on-the-fly-with-mailgun.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/03/31/creating-a-mobile-app.html"><h3>Creating a Mobile Content App with (Almost) Real Time Edits</h3></a>
		<div class="date">March 31, 2014</div>
	</div>
	<div class="col-8">
		<p>It’s not too often that we’re asked to put together a native mobile app at <a href="http://www.apcoworldwide.com">APCO Worldwide</a>, but it does happen from time to time. We’re a communications firm first and an app development firm second, and that means we have to plan for regular content additions, modifications and deletions that often need to happen immediately. We can’t afford to recompile code and go through an app submission process every time someone needs to add a new story to an app, so we have to bake some flexibility into the system itself.</p>

<p>We also like to give our communications teams (copywriters, speechwriters, etc.) the ability to edit their own content on the fly when they need to. It’s certainly easier for all parties concerned. Content changes don’t have to be worked into a development queue, and developers don’t need to go through the same quality control cycles over and over again if we build something flexible from the start. To this end, we’ve often opted to use Drupal for our CMS. We’ve trained our communications teams on how to use it and now have a predictable development pattern for the sites we build to deal with similar use cases. It gets hacky from time to time, but it works for a PR firm. </p>

<p>One of our comms teams came to us in January with a content rich app idea that needed to be native on both iOS and Android. We knew it would require regular updates with a minimum amount of fuss, so we needed to find a way to feed content to the app rather than store it all locally. We also needed the application that populated that feed to have an interface that was familiar to our communications team. We knew we could solve the second problem with either Drupal or Wordpress, but what to do with the first?</p>

<p>Enter one of my new favorite ways to spend taxpayer money: the Drupal <a href="https://drupal.org/project/contentapi">Content API</a> module. This project was put together jointly by the Federal Communications Commission and <a href="http://seabourneinc.com/">Seabourne Consulting</a>, and it does exactly what it sounds like: it makes a content API out of your Drupal website. There’s a nice point-and-click interface in the Drupal administrative console that allows you to select the content types you’d like to feature in your API, the endpoints you’d like to use, and the fields you’d like to include, then voilà - an XML-formatted API appears. It’s beautiful.</p>

<p>So we’ve now got a nice XML feed of all of the content that’s going to populate this app happily displayed out there on the web. Our users can add, delete and modify entries and the XML feed will automatically update. </p>

<p>Getting this data into the app was another story altogether. We followed these rough steps to build our system on both iOS and Android:
1. Connect to the API 
2. Download the main XML file, which lists all content 
3. Parse the XML file and check the IDs against our existing data present on the phone
4. Download any new or modified IDs
5. Lay out app for user content viewing</p>

<p>And that’s pretty much it. I won’t go into a detailed tutorial - I leaned heavily on another developer for much of the native app work - but I will share a few gotchas.</p>

<p>The Content API module takes a non-configurable approach to pagination. In the standard code, you get ten items per XML page, and that’s it. I understand the rationale for why a government-sponsored content API would want to be careful on how much data it allowed out at any one time, but that wasn’t going to work for this project. Around line 500 in <code>contentapi.module</code>, one finds the following code snippet:</p>

<p><code>php
$limit = (isset($_GET['limit'])) ? (integer)$_GET['limit'] : 10;
...
$limit_cap = variable_get('contentapi_limit', 10);
</code></p>

<p>Change those 10’s to 200’s and now we’re talking. I am ashamed of the inelegance of this hack, but it got the job done.</p>

<p>Our second headache was XML parsing on Android. When we had the first working build up and running, it took five minutes to download the initial feed on a new installation. Android does a great job of background task management, but five minutes for a set of downloads that were mostly text was unacceptable. We did our homework, and it turns out that the <a href="http://steveliles.github.io/comparing_java_xml_parsing_mechanisms_for_android.html">standard approaches for XML parsing are absolute garbage on Android</a>. As <a href="http://twitter.com/steveliles">Steve Liles</a> points out in the above post, it’s far more efficient to swap in Java’s SAX parser to manage your XML downloads. We got our full download time to about a minute - and given that we were also having to deal with PDFs and images, I’ll take it. </p>

<p>We had a lot of fun building this app and thinking through how to make it play nicely on multiple devices with an easy-to-use central administration console. We’d love for you to take a look at our <a href="https://play.google.com/store/apps/details?id=com.meetingsmeanbusiness.mmb">Android handiwork</a>. I’ll share the iOS version once it finishes the Apple review cycle. Enjoy!</p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/03/31/creating-a-mobile-app.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/03/26/open-source-search-technologies-for-human-beings-part-3.html"><h3>Open Source Search Technologies for Human Beings - Part 3</h3></a>
		<div class="date">March 26, 2014</div>
	</div>
	<div class="col-8">
		<p>In the <a href="http://josephmosby.com/2014/03/24/open-source-search-technologies-for-human-beings-part-1.html">first part</a> of this series, we talked about the nuts and bolts of search engines: how they create a nicely organized index of keywords and documents and use that index to find documents containing keywords. <a href="http://josephmosby.com/2014/03/25/open-source-search-technologies-for-human-beings-part-2.html">Part 2</a> walked us through Lucene, an open source search engine written in Java that turns our Part 1 idea of a search engine into a computer program. With Part 3, we’re going to build upon Lucene with Solr and Elasticsearch, two programs that use Lucene to create a fully-featured web search engine.</p>

<p>We saw that Lucene can do some basic indexing and searching, but it’s fairly limited. It can only handle plain text documents well, it doesn’t have any ability to connect to the web, and even the tiny little command-line application we used to “talk” to Lucene had to be built as a demonstration. Needless to say, Lucene just doesn’t have what we need to serve as a web search engine. That’s where Solr and Elasticsearch come in. They use Lucene as their core, but they tack on additional features in different ways to meet the needs of their customers. We’ll take a first look at Solr, the federal government’s legacy search engine, then follow it by showing the future with Elasticsearch.</p>

<h3 id="solr">Solr</h3>

<p><a href="https://lucene.apache.org/solr/">Solr</a> began as an enterprise search engine in 2004, and was designed for websites from the beginning. It was initially part of the closed source code owned by CNET, but was released as open source software when CNET donated the code to the Apache Software Foundation a a few years later. Solr has since become an integral part of the Lucene ecosystem to the point that the two programs are now maintained by the same development team. </p>

<p>Solr runs as an application server. Any program making use of a Solr server must make some sort of request to the server (such as adding documents to be indexed or querying for documents with “football” in the text). Solr will then respond to that request with search results, which the program can then display to the user, load into a web page or incorporate into a larger application. </p>

<p><img src="/images/solr_doc_1.png" alt="Diagram of a program adding a file to the Solr index" /></p>

<p>The popularity of Solr for years brought it a lot of support from developer communities across many different languages and platforms. Solr proudly boasts support for PHP, Ruby, Python, Drupal, Wordpress, and a stack of other platforms that make adoption easy for users regardless of their existing technology stack. It’s fast to set up, fast to run, and easy for an administrator to maintain through a web-based administrative interface.</p>

<p>That being said, Solr has a stack of limitations. It began as a centralized Java application, and it still requires a lot of familiarity with Java to run effectively. And all the Java in the world can’t make up for the fact that Solr was built to be run from a central location. Elasticsearch took a different approach.</p>

<h3 id="elasticsearch">Elasticsearch</h3>

<p><a href="http://www.elasticsearch.org/">Elasticsearch</a> is the new kid on the block of open source search engines. <a href="https://twitter.com/kimchy">Shay Baron</a> started writing the roots of Elasticsearch in 2004 with the Compass project, but soon realized that he would have to rewrite Compass to build it into a fully “scalable” system that could handle a substantial amount of search traffic at once without crashing. In 2010, Compass was rolled into the Elasticsearch project with all of the features needed to challenge Solr’s dominance.</p>

<p>Elasticsearch (which I’ll just abbreviate as ES from now on) was built from the ground up to be a distributed search platform rather than a centralized system like Solr. Whereas Solr has to handle each search request from a central hub, ES can split the workload over a cluster of search servers to speed up processing. Search starting to run slowly? Add more servers, no problem.</p>

<p><img src="/images/es_doc_1.png" alt="Diagram of a program adding a file to the Elasticsearch index, which consists of many servers" /></p>

<p>To be fair, Solr is now technically a distributed system as well through the addition of <a href="http://zookeeper.apache.org/">Zookeeper</a>. Zookeeper is a program designed to keep multiple servers in synchronization as a single Solr instance. It’s an afterthought, though, and Solr still is not capable of handling many of the advanced distribution features that ES boasts by default. </p>

<p>Elasticsearch also allows programmers to interact with a single RESTful API when they want to update and query the search engine. This is incredibly attractive to the average web developer who often did not study Java programming in school but interacts with RESTful APIs on a daily basis. With a single tailored request sent to ES’ API, developers have search results ready to go without the need for a full-featured Java application.</p>

<p>Modern search engines also have a specific syntax for creating complex queries (for example, typing “site:apache.org Solr” will return any results for Solr on the Apache website only), and Elasticsearch is no different. The search engine also comes with a stack of plugins available and programming libraries written for many of the more esoteric languages to complement the common options available to both ES and Solr developers.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Elasticsearch offers a number of benefits to web developers, and it’s easy to see why the federal government is making moves to convert Solr instances into Elasticsearch ones. RESTful APIs and distributed clusters simply make perfect sense in a web environment. I’ll be looking forward to seeing continued improvements in the federal government’s search capabilities as they work through the upgrade.</p>

<p>– special thanks to Kelvin Tan’s great side-by-side breakdown of the technical differences between Solr and Elasticsearch here: <a href="http://solr-vs-elasticsearch.com/">http://solr-vs-elasticsearch.com/</a></p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/03/26/open-source-search-technologies-for-human-beings-part-3.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/03/25/open-source-search-technologies-for-human-beings-part-2.html"><h3>Open Source Search Technologies for Human Beings - Part 2</h3></a>
		<div class="date">March 25, 2014</div>
	</div>
	<div class="col-8">
		<p>In the <a href="http://josephmosby.com/2014/03/24/open-source-search-technologies-for-human-beings-part-1.html">first part</a> of this series, we investigated the basics of how a search engine theoretically works. The process we described in part 1 didn’t actually require a computer at all - any person could theoretically follow those exact same steps. Indeed, writers of complex research materials did so for decades before the first computers were invented. </p>

<p>Though there is an entire profession based strictly around organizing and categorizing information and retrieving it at a later time (librarians), the average person doesn’t want to be doing that on a daily basis. We’ve got computers for that, but that means we have to write a program to perform all of those steps we don’t want to do ourselves. This brings us to <a href="https://lucene.apache.org/core/">Lucene</a>.</p>

<h3 id="lucene">Lucene</h3>

<p>To quote exactly from the official manual: “Lucene is a high-performance, full-featured text search engine library written entirely in Java.” Lucene performs all of the search engine features we described in part 1: it reads text-based documents, creates an index of those documents, and retrieves the documents based on search keywords. It does this quickly and efficiently with many features that make it appealing to computer programmers who wish to incorporate it into their applications. </p>

<p>Let’s take a quick tour of Lucene by playing around with its demo directly. </p>

<pre><code>java org.apache.lucene.demo.IndexFiles /{path}/lucene-4.7.0/licenses
</code></pre>

<p>With this command, we first call the Java available on most of our personal computers. Lucene is written entirely in Java, a programming language popular with the federal government and many large commercial enterprises. We then call a Java-specific Lucene command - IndexFiles - and ask Lucene to index all the files in the “licenses” directory. This will produce an index of all of the legal software license documents that apply to the use of Lucene. When we do this, Lucene will happily print out a stack of messages letting us know that it’s indexing:</p>

<p><code>
Indexing to directory 'index'...
adding /{path}/lucene-4.7.0/licenses/ant-1.8.2.jar.sha1
adding /{path}/lucene-4.7.0/licenses/ant-LICENSE-ASL.txt
adding /{path}/lucene-4.7.0/licenses/ant-NOTICE.txt
... so on and so forth...
</code></p>

<p>And now we have an index! Let’s query it for a search term:</p>

<p><code>
java org.apache.lucene.demo.SearchFiles
Enter query: 
GNU
Searching for: gnu
2 total matching documents
1. /{path}/lucene-4.7.0/licenses/javax.servlet-LICENSE-CDDL.txt
2. /{path}/lucene-4.7.0/licenses/servlet-api-LICENSE-CDDL.txt
</code></p>

<p>I entered the SearchFiles command, and Lucene immediately prompted me for a search term. Thinking that I might find some reference to the <a href="https://www.gnu.org/copyleft/gpl.html">GNU Public License</a> in a piece of open source software, I typed in “GNU” as my search term. Lucene found two files that contain the word “GNU” and returned them to me here. But if I try another term, it finds nothing at all:</p>

<p><code>
java org.apache.lucene.demo.SearchFiles
Enter query: 
football
Searching for: football
0 total matching documents
</code></p>

<p>There’s a lot going on behind the scenes here with even this tiny demo app, but the basics are quite simple. Lucene has followed the exact same process for indexing and searching that we described in part 1. But what if we need to parse through an HTML or Word document rather than a simple text document? We’ll need something a little bit more robust, which is where Solr and Elasticsearch come in… in <a href="http://josephmosby.com/2014/03/25/open-source-search-technologies-for-human-beings-part-3.html">part 3</a>. </p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/03/25/open-source-search-technologies-for-human-beings-part-2.html" data-via="josephmosby">Tweet</a>
	</div>
</div>

<div class="row">
	<div class="col-3">
		<a href="/2014/03/24/open-source-search-technologies-for-human-beings-part-1.html"><h3>Open Source Search Technologies for Human Beings - Part 1</h3></a>
		<div class="date">March 24, 2014</div>
	</div>
	<div class="col-8">
		<p>Search is one of those features that’s become so “baked in” to the way we experience the web that it’s often an afterthought for us as users. We peck a few well-chosen words into the Google search bar, press enter, and end up where we needed to be. It’s become a mental backup system to the point that we no longer even need to bookmark a link any more as long as we can remember the few keywords that will bring us back to the page. Though I develop websites every single day, I had never actually thought about the search technology that brings users to my page and allows them to find the content they wanted.</p>

<p>I was suddenly forced to confront my ignorance of search when I learned that the General Services Administration would be changing their search software from <a href="https://lucene.apache.org/solr/">Solr</a> to <a href="http://www.elasticsearch.org/">Elasticsearch</a>. Having no idea how either of them worked, I started doing my homework immediately. </p>

<h3 id="how-search-works">How Search Works</h3>

<p>Though the specific implementations vary across platforms, the core of any text-based search technology is the same. The subject matter will be broken down into small components that can be stored in an index that references back to the document in question. The name is not accidental: this works in the same way as a word index that points back to pages at the back of a heavy research book. As we add more documents to the index, this process is repeated and the index size and complexity increases. </p>

<p>In this example, our documents can be anything primarily composed of text. Web pages, Word documents or eBooks could all be comfortably fed into our search engine and happily indexed. Eventually, though, we’ll need to retrieve that information if we want a fully functional search engine. An index of extremely well-organized keywords and documents won’t do us any good if we never use it to retrieve the information we need. To do so, we’ll “query” the index by feeding it a keyword. The search engine will then check its index for all documents that match that keyword and return us the corresponding list of document. If we add more than one keyword, the search engine will query the index to find documents that show up for each individual keyword then compare the results to bring us documents that contain all of our keywords. </p>

<p>Let’s take a quick visual walk through this process. Say we have a document (NFL.doc) that we’d like to index. Our document contains quite a bit of text about the NFL, all of which will be broken down and inserted into our index.</p>

<p><img src="/images/NFLdoc.png" alt="Picture of a document that contains text about the NFL" /></p>

<p>Our indexing process is going to examine the text of the document, split out the words, and point those words back to NFL.doc.</p>

<p><img src="/images/index1.png" alt="Table of keywords that all correspond back to NFL.doc" /></p>

<p>We’ll then add these keyword/document pairings into our main index, which contains similar pairings for other documents.</p>

<p><img src="/images/index2.png" alt="Table of keyword/document pairings that contains NFL and MLS references" /></p>

<p>When a user searches for a term, the search engine will check the index and return the documents that correspond to that term. In this example, our user has searched for “football.”</p>

<p><img src="/images/search.png" alt="Input box prompting user to search. The user has entered &quot;football&quot; into the input box." /></p>

<p>Our example index only has a single entry for the word “football” - the NFL.doc document - and so our search engine returns that document to the user.</p>

<p><img src="/images/single_search_result.png" alt="Table showing a single keyword/document pairing that matches the word football with NFL.doc" /></p>

<p>And that’s the core of a search engine to get us started! In <a href="http://josephmosby.com/2014/03/25/open-source-search-technologies-for-human-beings-part-2.html">Part 2</a> I’ll talk a little bit about Lucene, the nuts and bolts of both Solr and Elasticsearch. In <a href="http://josephmosby.com/2014/03/25/open-source-search-technologies-for-human-beings-part-3.html">Part 3</a>, I’ll compare the two pieces of software to show how they each bring search technology to life for the web. </p>

		<a class="twitter-share-button" href="http://twitter.com/share" data-url="http://josephmosby.com/2014/03/24/open-source-search-technologies-for-human-beings-part-1.html" data-via="josephmosby">Tweet</a>
	</div>
</div>


<div class="row">
	<div class="col-offset-3 col-8">
		<div class="pagination">
			
			<a href="/page7" class="previous">Previous</a>
			

			<span class="page_number">Page: 8 of 9</span>

			
			<a href="/page9" class="next">Next</a>
			
		</div>
	</div>
</div>
			</div>
		</div>

		<div class="wrapper" id="footer">
			<div class="container">
				<div class="row">
					<div class="col-13">
						<p>Brought to you live from Washington, D.C.</p>
					</div>
				</div>
			</div>
		</div>

		<script src="app.js"></script>

		<script>
	
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	    ga('create', 'UA-45638065-1', 'josephmosby.com');
	    ga('send', 'pageview');
	  
	  	</script>

  		<script>
		window.twttr=(function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return;js=d.createElement(s);js.id=id;js.src="https://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);t._e=[];t.ready=function(f){t._e.push(f);};return t;}(document,"script","twitter-wjs"));
		</script>

	</body>

</html>